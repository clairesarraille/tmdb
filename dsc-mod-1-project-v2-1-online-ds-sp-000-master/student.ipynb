{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Claire Sarraille\n",
    "* Student pace: self paced\n",
    "* Scheduled project review date/time:  Monday June 14th 1pm PST\n",
    "* Instructor name: Jeff Herman\n",
    "* Project Repo URL: https://github.com/clairesarraille/mod1finproj/tree/main/dsc-mod-1-project-v2-1-online-ds-sp-000-master\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "source": [
    "Set environment before running this script with: conda activate learn-env\n",
    "Import datascience libraries:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datascience libraries:\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import libraries for fetching and formatting data:\n",
    "from tmdbv3api import TMDb, Discover, Movie\n",
    "import os\n",
    "\n",
    "# Import libraries for performing operations:\n",
    "from math import ceil\n",
    "\n",
    "# Load classes from tmdbv3api - a python library for The Movie Database (TMDb) API\n",
    "tmdb = TMDb()\n",
    "discover = Discover()\n",
    "movie = Movie()\n",
    "\n",
    "# Store my API key in my previously set environment variable as a tmdb.api_key string\n",
    "priv_api_key = os.environ.get('TMDB_PRIVATE_API_KEY')\n",
    "tmdb.api_key = priv_api_key"
   ]
  },
  {
   "source": [
    "Preview of discover.discover_movies data:\n",
    "\n",
    "I used this function to quickly scan a sub-set of titles & tweak variables such as:\n",
    "- 'with_original_language': 'en'\n",
    "\n",
    "I used a slightly different function to pretty-print samples of all info for a sub-set of movies. See appendix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_sample_tmdb(m, m_r, p, y):\n",
    "    print()\n",
    "    print(f\"Year is: {y}\")\n",
    "    print(f\"Page is: {p +1}\")\n",
    "    print(f\"There are {len(m[y])} movies in movies dict for {y}\")\n",
    "    for d in m_r[0:1]:\n",
    "        print(\"sample original title: \",(dict(d))['original_title'])\n",
    "    print()"
   ]
  },
  {
   "source": [
    "Function to extract 500 movies each for years 2016-2021 inclusive, sorted by revenue descending\n",
    "This line is commented out in the code below, to preserve space in the notebook:\n",
    "- print_sample_tmdb(movies, movies_running, page, year)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This function uses the discover.discover_movies() method from the tmdbv3api package to intake initial movie data:\n",
    "\n",
    "# Define Constants\n",
    "# Constants are usually defined on a module level and written in all capital letters with underscores separating words\n",
    "N_YEAR_RANGE = range(2016, 2022)  # grab 2016-2021 data, inclusive\n",
    "N_RESULT = 500  # Enter number of results desired for each year\n",
    "N_RESULT_PAGE = 20  # Discover() class returns 20 results per page\n",
    "# Num pages = Num results / num results per page, rounded UP using math.ceil\n",
    "N_PAGES = ceil(N_RESULT / N_RESULT_PAGE)\n",
    "\n",
    "# Instantiate empty dictionary movies to store outside of the following loops,\n",
    "# because you want to use movies after loops are finished executing\n",
    "movies = {}\n",
    "\n",
    "# Function to grab data from discover.discover_movies:\n",
    "\n",
    "\n",
    "def return_discover_movies():\n",
    "    for year in N_YEAR_RANGE:  # iterate through years 2000-2019 inclusive\n",
    "        # Keys are integers for each year\n",
    "        # Values will be lists of tmdbv3api objects, converted to dictionaries\n",
    "        movies[year] = []\n",
    "        for page in range(0, N_PAGES):\n",
    "            # For N_PAGES, create list movies_running, querying results by year, page, & sort revenue desc\n",
    "            # The objects within movies_running 'tmdbv3api.as_obj.AsObj' objects, and will need to be converted to dictionaries later\n",
    "            movies_running = discover.discover_movies({\n",
    "                # We want to sort by revenue so that we make sure we're getting the highest grossing movies in each batch of 500\n",
    "                'sort_by': 'revenue.desc', \n",
    "                'primary_release_year': str(year),\n",
    "                # API is 1 indexed - so we grab pages 1 to N_PAGES inclusive\n",
    "                'page': str(page + 1),\n",
    "                'vote_count.gte': 1,    # Movies with 0 votes are likely among the most unpopular. OK to filter by at least 1 vote.\n",
    "                'with_original_language': 'en' # Since our studio is still in R&D mode, we'll focus on movies originally shot in English\n",
    "            })\n",
    "            # For each year in our movies dictionary, store the year as a key (datatype list) in dictionary \"movies\"\n",
    "            # Then, iterate through 'tmdbv3api.as_obj.AsObj' objects in movies_running for N_PAGES, converting each object as a dictionary\n",
    "            # For each year we will have a list of dictionaries, and each dictionary is a set of information for a single movie\n",
    "            # .extend used rather than .append in order to extend our list by >1 items at once\n",
    "            movies[year].extend([dict(tmdb_obj)\n",
    "                                for tmdb_obj in movies_running])\n",
    "            \n",
    "            # print_sample_tmdb(movies, movies_running, page, year)  # Preview original movie titles:\n",
    "\n",
    "\n",
    "# Now we have our dictionary movies, with years 2000-2019 inclusive, each with 100 movies in each list from that year\n",
    "# We didn't need to return movies in the definition of this function, because movies was declared before the function\n",
    "return_discover_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The total movie count returned from our return_discover_movies() function above is: \n3000\n\nThe keys in our movies dictionary are:\ndict_keys([2016, 2017, 2018, 2019, 2020, 2021])\n"
     ]
    }
   ],
   "source": [
    "# Sanity check there are 3,000 titles in movies dictionary\n",
    "# Print ALL movie titles and ids from movies dictionary to qa_titles.txt for data-cleaning prep: manual review\n",
    "movie_count = 0\n",
    "for year in movies:\n",
    "    for moo_vie in range(0,len(movies[year])):\n",
    "        movie_count +=1\n",
    "        my_string = f\"{movies[year][moo_vie]['title']}       {movies[year][moo_vie]['id']}\"\n",
    "        with open(\"/Users/clairesarraille/git-repos/mod1finproj/dsc-mod-1-project-v2-1-online-ds-sp-000-master/qa_files/qa_titles.txt\", \"a+\",encoding='utf-8') as file_object:\n",
    "            # Move read cursor to the start of file.\n",
    "            file_object.seek(0)\n",
    "            data = file_object.read(100)\n",
    "            if len(data) > 0 :\n",
    "                 file_object.write(\"\\n\")\n",
    "            file_object.write(my_string)\n",
    "\n",
    "# Print movie counts in movies dict:\n",
    "print(\"The total movie count returned from our return_discover_movies() function above is: \")\n",
    "print(movie_count)\n",
    "\n",
    "# Print keys in movies dict:\n",
    "print()\n",
    "print(\"The keys in our movies dictionary are:\")\n",
    "print(movies.keys())\n"
   ]
  },
  {
   "source": [
    "While scanning the above list, I found the following that I'll use to develop some data clean-up methods:\n",
    "\n",
    "- These don't look legitimate:\n",
    "    - movie_02    813075\n",
    "    - movie_01    813064\n",
    "    - welcome_home.exe    82418\n",
    "    - jji    763071\n",
    "\n",
    "- There's a double entry for this movie:\n",
    "    - Split    358364\n",
    "    - Split    381288\n",
    "\n",
    "- Not in English, this one I later caught when running the analysis to find non-ascii characters:\n",
    "    - عتيج    676624\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bigfoot vs the Illuminati\n784281\n\nCheez-It's & Chili\n802103\n\nA Tiny House Christmas\n796438\n\n"
     ]
    }
   ],
   "source": [
    "# Check that API is working properly by spot-checking movie titles/ids between methods discover.discover_movies and movie.details()\n",
    "\n",
    "# Expected data (from discover.movies)\n",
    "# Bigfoot vs the Illuminati\n",
    "# 784281\n",
    "my_result = movie.details(784281)\n",
    "print(my_result.title)\n",
    "print(my_result.id)\n",
    "print()\n",
    "\n",
    "# Expected data (from discover.movies)\n",
    "# Cheez-It's & Chili\n",
    "# 802103\n",
    "my_result = movie.details(802103)\n",
    "print(my_result.title)\n",
    "print(my_result.id)\n",
    "print()\n",
    "\n",
    "# Expected data (from discover.movies)\n",
    "# A Tiny House Christmas\n",
    "# 796438\n",
    "my_result = movie.details(796438)\n",
    "print(my_result.title)\n",
    "print(my_result.id)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our movies dictionary has keys for years 2016-2021\n",
    "# The value for each year is a list of dictionaries. Each dictionary is a movie.\n",
    "# To turn this data into a Pandas datastructure, we iterate through all the years and all the dictionaries in each year\n",
    "# Our result, movies_list_of_dict is a simple list of all the movie dictionaries.\n",
    "# All we have to do then is use pd.DataFrame() to use the keys as column headers and the values as the cell values in rows.\n",
    "\n",
    "movies_list_of_dict = [movie_d for movie_yr in movies for movie_d in movies[movie_yr]]\n",
    "df_movies = pd.DataFrame(movies_list_of_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       title                     backdrop_path\n",
       "531  Get Out  /vZ7EVk7FaNEWYqlVWbFLHP8Z0LU.jpg"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>backdrop_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>531</th>\n      <td>Get Out</td>\n      <td>/vZ7EVk7FaNEWYqlVWbFLHP8Z0LU.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "source": [
    "# Preview df_movies:\n",
    "# First three movies:\n",
    "df_movies.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      adult                     backdrop_path        genre_ids      id  \\\n",
       "2997  False  /qtJGWUTaXuPVSqJOXSWoZCqucEr.jpg      [35, 10749]  796126   \n",
       "2998  False                              None  [80, 18, 10749]  796124   \n",
       "2999  False                              None             [18]  796034   \n",
       "\n",
       "     original_language      original_title  \\\n",
       "2997                en           Bad Cupid   \n",
       "2998                en         Ride or Die   \n",
       "2999                en  Oklahoma Mon Amour   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "2997  Archie is a God on a mission to ensure that tr...       1.400   \n",
       "2998  Ashley, a fierce friend to Mandy, takes the ph...      31.159   \n",
       "2999  Rural United States and modern urban Mexico me...       0.600   \n",
       "\n",
       "                           poster_path release_date               title  \\\n",
       "2997  /9nSHoZpU8jFHjKwJ895bzkjPldG.jpg   2021-02-11           Bad Cupid   \n",
       "2998  /77S8LQNkB0se2nk15X1d22QV1d1.jpg   2021-02-09         Ride or Die   \n",
       "2999                              None   2021-04-24  Oklahoma Mon Amour   \n",
       "\n",
       "      video  vote_average  vote_count  \n",
       "2997  False           6.0           3  \n",
       "2998  False           4.0           2  \n",
       "2999  False           5.0           1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adult</th>\n      <th>backdrop_path</th>\n      <th>genre_ids</th>\n      <th>id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>poster_path</th>\n      <th>release_date</th>\n      <th>title</th>\n      <th>video</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2997</th>\n      <td>False</td>\n      <td>/qtJGWUTaXuPVSqJOXSWoZCqucEr.jpg</td>\n      <td>[35, 10749]</td>\n      <td>796126</td>\n      <td>en</td>\n      <td>Bad Cupid</td>\n      <td>Archie is a God on a mission to ensure that tr...</td>\n      <td>1.400</td>\n      <td>/9nSHoZpU8jFHjKwJ895bzkjPldG.jpg</td>\n      <td>2021-02-11</td>\n      <td>Bad Cupid</td>\n      <td>False</td>\n      <td>6.0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2998</th>\n      <td>False</td>\n      <td>None</td>\n      <td>[80, 18, 10749]</td>\n      <td>796124</td>\n      <td>en</td>\n      <td>Ride or Die</td>\n      <td>Ashley, a fierce friend to Mandy, takes the ph...</td>\n      <td>31.159</td>\n      <td>/77S8LQNkB0se2nk15X1d22QV1d1.jpg</td>\n      <td>2021-02-09</td>\n      <td>Ride or Die</td>\n      <td>False</td>\n      <td>4.0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2999</th>\n      <td>False</td>\n      <td>None</td>\n      <td>[18]</td>\n      <td>796034</td>\n      <td>en</td>\n      <td>Oklahoma Mon Amour</td>\n      <td>Rural United States and modern urban Mexico me...</td>\n      <td>0.600</td>\n      <td>None</td>\n      <td>2021-04-24</td>\n      <td>Oklahoma Mon Amour</td>\n      <td>False</td>\n      <td>5.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 237
    }
   ],
   "source": [
    "# Last three movies:\n",
    "df_movies.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3000, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 233
    }
   ],
   "source": [
    "# See number of rows and columns, respectively:\n",
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3000 entries, 0 to 2999\nData columns (total 14 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   adult              3000 non-null   bool   \n 1   backdrop_path      1931 non-null   object \n 2   genre_ids          3000 non-null   object \n 3   id                 3000 non-null   int64  \n 4   original_language  3000 non-null   object \n 5   original_title     3000 non-null   object \n 6   overview           3000 non-null   object \n 7   popularity         3000 non-null   float64\n 8   poster_path        2843 non-null   object \n 9   release_date       3000 non-null   object \n 10  title              3000 non-null   object \n 11  video              3000 non-null   bool   \n 12  vote_average       3000 non-null   float64\n 13  vote_count         3000 non-null   int64  \ndtypes: bool(2), float64(2), int64(2), object(8)\nmemory usage: 287.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Are there any null values?\n",
    "# It looks like the only null values are for backdrop_path (suffix for movie's image URL)\n",
    "# In other words, no missing data for this analysis so far.\n",
    "df_movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 254
    }
   ],
   "source": [
    "type(df_movies['title'].str.contains('Get Out'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       title                     backdrop_path\n",
       "531  Get Out  /vZ7EVk7FaNEWYqlVWbFLHP8Z0LU.jpg"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>backdrop_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>531</th>\n      <td>Get Out</td>\n      <td>/vZ7EVk7FaNEWYqlVWbFLHP8Z0LU.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 253
    }
   ],
   "source": [
    "# Just for fun, let's explore one movie's backdrop_path - what do we do with this field?\n",
    "# One of my favorite movies from the past 6 years is Get Out - so lets find it in df_movies\n",
    "# I accessed a subset of df_movies with .loc using a pandas series of boolean values (title contains 'Get Out')\n",
    "get_out = df_movies[['title', 'backdrop_path']].loc[(df_movies['title'].str.contains('Get Out'))]\n",
    "get_out"
   ]
  },
  {
   "source": [
    "Example back_drop path appended to https://image.tmdb.org/t/p/w500/ to get back the w500 size:\n",
    "- https://image.tmdb.org/t/p/w500/vZ7EVk7FaNEWYqlVWbFLHP8Z0LU.jpg\n",
    "\n",
    "\n",
    "- I embedded it here using <img src=\"get_out.png\"\\>, and storing the actual image get_out.png in the folder with this notebook:\n",
    "\n",
    "<img src=\"get_out.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "metadata": {},
     "execution_count": 235
    }
   ],
   "source": [
    "# Next, we'll create a list of movie ids we have stored in df_movies\n",
    "# We'll use that list to get more detailed movie info from the tmdbv3api library's movie.details() method\n",
    "\n",
    "# Create list of movie ids from df_movies:\n",
    "movie_id_list = df_movies['id'].tolist()\n",
    "\n",
    "# Check length of list:\n",
    "len(movie_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "781739\n"
     ]
    }
   ],
   "source": [
    "# Find any movies that would throw an error when passed to movie.details()\n",
    "# Under the hood of the tmdbv3api library we are simply using the GET method to retrieve data from the TMDb server at a specified resource.\n",
    "# The TMDb API behaves such that if the movie id doesn't exist in the /movie/{movie_id} resource, we'll get an error back\n",
    "# Let's see if any of our movie ids would throw such an error:\n",
    "\n",
    "my_keys = ['adult', 'budget', 'genres', 'id', 'imdb_id', 'original_language', 'original_title', 'popularity','production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'title', 'keywords']\n",
    "\n",
    "details_list = []\n",
    "\n",
    "for id_index in movie_id_list:\n",
    "    try:\n",
    "        r = movie.details(id_index)\n",
    "        details_list.extend({my_key: dict(r).get(my_key) for my_key in my_keys})\n",
    "    except:\n",
    "        print(id_index)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     title      id  popularity  \\\n",
       "2396  Hero  781739         0.0   \n",
       "\n",
       "                                               overview release_date  \n",
       "2396  Hero was diagnosed with cancer at the age of 2...   2020-12-31  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>id</th>\n      <th>popularity</th>\n      <th>overview</th>\n      <th>release_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2396</th>\n      <td>Hero</td>\n      <td>781739</td>\n      <td>0.0</td>\n      <td>Hero was diagnosed with cancer at the age of 2...</td>\n      <td>2020-12-31</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 258
    }
   ],
   "source": [
    "# Out of curiosity, lets look at the details for this movie:\n",
    "df_movies[['title', 'id', 'popularity', 'overview', 'release_date']].loc[(df_movies['id'] == 781739)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hero was diagnosed with cancer at the age of 22. After losing faith in himself, and getting ready to give up, he found support in a place he felt safe - The Furry Fandom. Now, Hero is getting his first fursuit. This is his story.\n"
     ]
    }
   ],
   "source": [
    "print(df_movies.loc[(df_movies['id'] == 781739), 'overview'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is one movie that threw an error. Check it out in our df_movies and then remove from movie_id_list\n",
    "movie_id_list.remove(781739)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_keys = ['adult', 'budget', 'genres', 'id', 'imdb_id', 'original_language', 'original_title', 'popularity','production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'title', 'keywords']\n",
    "\n",
    "details_list = []\n",
    "\n",
    "for id_index in movie_id_list:\n",
    "    try:\n",
    "        r = movie.details(id_index)\n",
    "        details_list.extend({my_key: dict(r).get(my_key) for my_key in my_keys})\n",
    "    except:\n",
    "        print(id_index)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_list_ids = [271110, 330459, 127380, 269149, 278927, 328111, 209112, 259316, 293660, 297761]\n",
    "\n",
    "my_keys = ['adult', 'budget', 'genres', 'id', 'imdb_id', 'original_language', 'original_title', 'popularity','production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'title', 'keywords']\n",
    "\n",
    "# In case any of the movies are missing any of the above keys, use:\n",
    "# dict.get(key, default_value)\n",
    "# This is one way in which I dealt with missing values that I was receiving in the API\n",
    "\n",
    "details_list = []\n",
    "details_list.extend({my_key: dict(movie.details(id_index)).get(my_key) for my_key in my_keys} for id_index in movie_id_list)\n",
    "print(details_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert details_list to a pandas df:\n",
    "df_details = pd.DataFrame(details_list)\n",
    "df_details[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take initial stock:\n",
    "df_details.index\n",
    "df_details.info()\n",
    "df_details.columns\n",
    "df_details.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future: Could check original language by connecting with IMDb & checking language from there - could also use LetterBox\n",
    "# Detect non-english strings in title and remove them from df_details:\n",
    "\n",
    "pd.set_option('display.max_rows', df_details.shape[0]+1) # Set display option so that we can see all rows because we will likely manually review the values:\n",
    "\n",
    "# Create function to detect non-english strings:\n",
    "def detect_en(ascii_string):\n",
    "    try:\n",
    "        ascii_string.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "column_names = [\"id\", \"title\"]\n",
    "flag_non_en = pd.DataFrame(columns = column_names)\n",
    "for item in df_details.loc[:, 'title']:\n",
    "    if isEnglish(item) == False:\n",
    "        flag_non_en = flag_non_en.append(df_details[['id','title']].loc[df_details['title'] == item])\n",
    "# print(flag_non_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of movie ids that you want to remove from df_details, based on internet research to see if original language is English:\n",
    "# 720980      Express Yourself: Die Tänzer der Queen of Pop\n",
    "# 676624                                               عتيج\n",
    "# 671272                              Óleos en la oscuridad\n",
    "# 664648                                          Crisálida\n",
    "# 692856                                              Avīci\n",
    "# 691836                      Avante (Ao Vivo em São Paulo)\n",
    "# 680817                                      Hranice práce\n",
    "# 676912                                            Sátiros\n",
    "# 703348                                               عقلي\n",
    "# 720570                                   maníaco da ponte\n",
    "# 832125                                  Ghostemane: Ímpio\n",
    "# 806831                 História Secreta do Pop Brasileiro\n",
    "# 783999        Crimes de haine en Amérique : l'inquiétante\n",
    "# 740354                                          Bach-Hông\n",
    "# 793311                                   Toilette d’amour\n",
    "# 787619                                           Czyściec\n",
    "# 832310                                           Verrückt\n",
    "# 822161                                         ¿Libertad?\n",
    "# 802434                                              Acéré\n",
    "\n",
    "\n",
    "# Remove rows with these ids from df_details:\n",
    "non_eng_ids = [720980, 676624, 671272, 664648, 692856, 691836, 680817, 676912, 703348, 720570, 832125, 806831, 783999, 740354, 793311, 787619, 832310, 822161, 802434]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the object columns and convert each variable to a separate Boolean column\n",
    "# Make Keywords column one long string\n",
    "my_sample = df_details.loc[0:5, 'genres']\n",
    "type(my_sample)\n",
    "my_sample\n",
    "for mystery in my_sample:\n",
    "    print(type(mystery))\n",
    "    print(type(mystery[0]))\n",
    "    print(mystery)\n",
    "# df_new = pd.json_normalize(df_details, 'genres', ['id','title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_list_of_dict(val):\n",
    "    val = [dict(x) for x in val]\n",
    "    return val\n",
    "\n",
    "#   movies[year].extend([dict(tmdb_obj) for tmdb_obj in movies_running])\n",
    "            # Preview original movie titles:\n",
    "# def convert_to_list_of_dict(val):\n",
    "#     list_dict_new = []\n",
    "#     for val_obj_tmdb in val:\n",
    "#         list_dict_new.append(dict(val_obj_tmdb))\n",
    "#         return list_dict_new\n",
    "\n",
    "\n",
    "df_details['genres_list_dict'] = df_details.loc[:,'genres'].apply(convert_to_list_of_dict)\n",
    "\n",
    "my_sample = df_details.loc[0:5, 'genres_list_dict']\n",
    "for mystery in my_sample:\n",
    "    print(type(mystery))\n",
    "    print(type(mystery[0]))\n",
    "    print(mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This normalization method doesn't quite work:\n",
    "df_norm_details = pd.DataFrame(df_details['genres_list_dict'].tolist())\n",
    "df_norm_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cat_list = df_details['genres_list_dict'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cat_list[0:10]\n",
    "# First list is for movie id 271110 -- check that those genre values are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop adult column:\n",
    "df.drop('DESC', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-order columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide what to do with these\n",
    "# These don't look legitimate:\n",
    "movie_02\n",
    "813075\n",
    "\n",
    "movie_01\n",
    "813064\n",
    "\n",
    "welcome_home.exe\n",
    "82418\n",
    "\n",
    "jji\n",
    "763071\n",
    "\n",
    "# There's a double entry for this movie:\n",
    "Split\n",
    "358364\n",
    "Split\n",
    "381288"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('learn-env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "5d1f83e9c63cec2de7bdeb43eb17fdae110b98c2255761b9e5cd119be6dbfe82"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}